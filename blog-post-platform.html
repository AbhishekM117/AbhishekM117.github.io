<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>From Zero to KPI: BigQuery Data Warehouse for IoT</title>
    <style>
        body {
            font-family: 'Poppins', sans-serif;
            line-height: 1.7; /* Increased line height for better readability */
            margin: 0;
            padding: 0;
            background-color: #f8f8f8;
            color: #333;
        }
        .container {
            max-width: 900px;
            margin: 40px auto;
            padding: 30px; /* Increased padding */
            background-color: white;
            box-shadow: 0 0 15px rgba(0,0,0,0.1);
            border-radius: 8px;
        }
        h1 {
            color: #004D7A;
            text-align: center;
            margin-bottom: 25px;
            font-size: 2.5em;
        }
        h2 {
            color: #0077B6;
            border-bottom: 3px solid #eee; /* Thicker separator */
            padding-bottom: 8px;
            margin-top: 40px;
            font-size: 1.8em;
        }
        h3 {
            color: #555;
            margin-top: 25px;
            font-size: 1.4em;
        }
        p, ul, ol {
            margin-bottom: 18px;
        }
        ul {
            list-style-type: disc;
            margin-left: 30px;
        }
        .header-image-container {
            width: 100%;
            height: 400px; /* Taller image */
            overflow: hidden;
            margin-bottom: 35px;
        }
        .header-image {
            width: 100%;
            height: 100%;
            object-fit: cover;
            border-radius: 8px;
        }
        .back-link {
            display: block;
            margin-top: 50px;
            text-align: center;
            color: #0077B6;
            text-decoration: none;
            font-weight: 600;
        }
        .callout {
            border-left: 4px solid #F0A500;
            background-color: #FFFBEA;
            padding: 15px 20px;
            margin: 20px 0;
            font-style: italic;
        }
    </style>
</head>
<body>
    <div class="container">
        <a href="javascript:history.back()" class="back-link">← Back to Portfolio</a>
        <h1>From Zero to KPI: Architecting a BigQuery Data Warehouse for IoT Telemetry—A War Story</h1>
        
        <div class="header-image-container">
            <img src="./assets/Micromobility_14.png" alt="Micromobility bike and dock from PORT" class="header-image" />
        </div>

        <p>Picture this: I joined Port as the first (and only) Principal Data Analyst, tasked with transforming siloed data assets into a unified, executive-ready platform. Port’s rapid growth meant bike telemetry data—GPS pings, battery states, lock/unlock events—was flowing in at high velocity, demanding a robust new architecture to support our scale. Our mission was clear: build the single source of truth, secure it for governance, and make it ready for serious analytics.</p>

        <p>This journey required us to move from complex, fragmented systems to a controlled, cloud-native architecture using GCP’s ecosystem. It wasn't just a technical build; it was the foundation for all strategic decision-making that followed.</p>

        <h2>Phase 1: Taming the Telemetry Beast (Ingestion & Velocity)</h2>
        <p>IoT data presents a unique challenge: high volume, high velocity, and the constant risk of data loss during peak load. We implemented a multi-tiered ingestion architecture to ensure maximum durability and scalability, ensuring that not a single crucial bike state change was ever missed.</p>
        
        <h3>1.1 Real-time Stream Architecture for Resiliency:</h3>
        <ul>
            <li><strong>The Buffer (Cloud Pub/Sub):</strong> We started by funneling everything into <b>Cloud Pub/Sub</b>. This scalable messaging queue acts as our safety layer, completely decoupling data producers (the bikes) from BigQuery consumers. This guarantees data integrity, regardless of downstream latency during traffic spikes.</li>
            <li><strong>The Cleaner (Cloud Dataflow):</strong> For serverless stream processing, <b>Cloud Dataflow (Apache Beam)</b> handles the immediate needs. Its job is to perform light transformations, schema validation (essential for ensuring valid location data), and event enrichment. It uses the <b>BigQuery Storage Write API</b> for efficient, <b>exactly-once delivery semantics</b>, which is non-negotiable for accurate IoT state tracking.</li>
        </ul>

        <h3>1.2 Batch Data Ingestion (Transactional Data):</h3>
        <p>Operational data (user accounts, bookings) was handled using an modern ELT and Change Data Capture (CDC) strategy, minimizing disruption to the production databases.</p>
        <ul>
            <li><b>CDC with Datastream:</b> We utilized Datastream for serverless Change Data Capture (CDC) from operational databases, ensuring near-real-time replicas of transactional data land directly in BigQuery. This eliminates the headache of building complex batch connectors.</li>
            <li><b>Optimized Loading:</b> For high-throughput scenarios, we leverage the <b>BigQuery Data Transfer Service (DTS)</b> for initial bulk loads and robust pipelines.</li>
        </ul>

        <h2>Phase 2: The Multi-Layer BigQuery Data Warehouse</h2>
        <p>BigQuery was chosen for its ability to scale compute and storage independently, offering us phenomenal performance at a manageable cost. We enforced a strict three-layer modeling paradigm to ensure security, auditability, and speed.</p>
        
        <h3>2.1 The Layered Approach (RAW, STG, MART):</h3>
        <ul>
            <li><b>RAW Layer:</b> The immutable landing zone. Contains exact copies of all payloads and CDC records, partitioned by ingestion date. Used only for auditing and debugging.</li>
            <li><b>STAGING Layer (The Workshop):</b> Data is standardized, cleaned, and de-duplicated here. This is where <b>Partitioning and Clustering</b> were aggressively applied (e.g., partitioned by time, clustered by `device_id` or `user_id`) to optimize query performance and control costs.</li>
            <li><b>MART Layer (The Storefront):</b> The consumption layer. Modeled almost exclusively in <b>Star Schemas</b> (`fact_rides`, `dim_users`) to ensure BI tools (and executives) get consistent, fast answers.</li>
        </ul>
        <div class="callout">
            Fun fact: One of my first quick wins was optimizing a core finance query running against the STAGING layer—it dropped from a painful 2.5 minutes to a snappy 8 seconds just by applying thoughtful clustering. That’s the power of good architecture!
        </div>

        <h2>Phase 3: Control, Governance, and Orchestration</h2>
        <p>Data reliability is paramount. This phase was about ensuring high data quality and auditability by treating our transformations like production code, enforced by Airflow and Dataform.</p>

        <h3>3.1 GitOps for Transformation (Airflow & Dataform):</h3>
        <ul>
            <li><b>Orchestration (Cloud Composer):</b> We deployed <b>Cloud Composer (managed Airflow)</b> to manage the execution order and dependencies of our transformation jobs (DAGs).</li>
            <li><b>Transformation Logic (Dataform):</b> All transformation logic was managed using <b>Dataform</b> (native GCP). Dataform enforces <b>CI/CD, code review, and version control</b> (GitOps) for all SQL logic, guaranteeing auditability of every metric change.</li>
            <li><b>Data Quality and Assertions:</b> We embedded <b>data assertions</b> directly into Dataform's models (e.g., checking for null keys or unexpected duplicates). If an assertion fails, Airflow immediately halts the pipeline, preventing corrupt data from hitting executive dashboards—this is how we enforce our critical SLA.</li>
        </ul>

        <h3>3.2 Security, PII, and GDPR by Design:</h3>
        <p>Given the nature of micro-mobility data, governance wasn't optional—it was a core design feature.</p>
        <ul>
            <li><b>PII Segregation:</b> We strictly mapped all PII fields. Access was layered: Analysts query the aggregated MART layer; Governance teams have controlled access to RAW/STG.</li>
            <li><b>BigQuery Access Controls:</b> We used <b>Policy Tags (Column-Level Security)</b> on PII fields and created <b>Authorized Views</b> to expose necessary aggregated data in the MART layer while permanently masking the underlying PII columns. This is a crucial security barrier.</li>
            <li><b>Automated Governance:</b> The platform was designed to automate GDPR retention policies, utilizing BigQuery expiration tools to ensure data outside its mandated lifecycle is automatically purged.</li>
        </ul>

        <h2>Phase 4: Fueling the Future (Consumption and ML Readiness)</h2>
        <p>The platform’s ultimate value lies in its flexibility, supporting both C-suite reporting and future ML innovation.</p>

        <h3>4.1 BI and Stakeholder Alignment:</h3>
        <ul>
            <li><b>Looker (Governed BI):</b> Used as the semantic BI layer for executive KPIs and board-grade reporting. Looker’s modeling ensures consistent metric definition (LTV, CAC) company-wide.</li>
            <li><b>Operational BI (Power BI/Metabase):</b> Used for rapid operational dashboards where <b>low decision latency</b> is critical (as seen in the fleet pressure analysis case study).</li>
        </ul>

        <h3>4.2 ML Readiness and Optimization:</h3>
        <ul>
            <li><b>Feature Engineering:</b> The clean MART layer is designed to be the input for ML. Data scientists can easily query the governed data, enabling rapid feature generation for models deployed via Vertex AI.</li>
            <li><b>Cost Management:</b> We enforced strict query best practices (no `SELECT *`), optimized tables with partitioning and clustering, and leveraged <b>Incremental Materialization</b> (via Dataform/dbt) for large tables to control costs and improve build speed.</li>
        </ul>

        <p>Ultimately, building this platform wasn't just a technical exercise; it was the essential step that moved Port from reacting to data to actively driving its business strategy. This architecture provides the reliability, security, and scalability needed to support Port's high-velocity operations and all its strategic initiatives.</p>

        <a href="javascript:history.back()" class="back-link">← Back to Portfolio</a>
    </div>
</body>
</html>